# Методы оценки и отладки моделей

## Конвеер

Можно объединить несколько преобразователей в конвеер при помощи класс Pipeline.

```
Pipeline([ (NAME, TRANSFORMER) ]).fit(X_train, y_train).predict(X_test)
```

Схематично это выгдядит так:

![image](https://user-images.githubusercontent.com/25401699/222958588-ad12be8e-aa58-462d-a397-a09dbc3ca4b2.png)

## Перекрестная проверка

Если мы хотим более правильно оценить точность модели на исходных данных, то
можно разбить данные на k блоков и сделать k тестов, в каждом из которых
один из блоков будет тестовым, а остальные учебными.

![image](https://user-images.githubusercontent.com/25401699/222959194-f1181ad0-a5d3-4568-8cfa-e310bac4800c.png)

Есть функция:

```
cross_val_score(pipeline, X_train, y_train, cv = 10)
```

## Кривая обучения

Мы хотим получить зависимость точности модели от размера выборки.
Оптимум должен выглядеть вот так:

![image](https://user-images.githubusercontent.com/25401699/223056659-ee295e7a-3839-43b6-938f-609780c2fa27.png)

На нашем тестовом примере будет так:

![image](https://user-images.githubusercontent.com/25401699/223056796-9e7dcec9-4136-45d8-b710-c1a18d512ad7.png)

Для построения кривой у нас есть функция:

```
train_sizes, train_scores, test_scores = learning_curve(estimator=pipe, X=X_train, y=y_train, train_sizes=np.linspace(0.1, 1.0, 10), cv=10, n_jobs=1)
```

Тут мы передаем в параметры данные, модель и сетку размеров для тестирования, причем тестирование происходит перекрестной проверкой, за что отвечает параметр cv.

## Проверочная кривая

Здесь мы строим зависимость точности модели от какого-нибудь ее гиперпараметра, например от
постоянной регуляризации.

Используем функцию:

```
train_scores, test_scores = validation_curve(estimator=pipe, X=X_train, y=y_train, param_name='clf__C', param_range=param_range, cv=10)
```

Тут нужно указать параметр, его диапазон и кол. блоков для перекрестной проверки.

Получим что-то такое:

![image](https://user-images.githubusercontent.com/25401699/223059687-6ed4b542-68e4-43de-93f3-10daa2b70328.png)

## Сеточный поиск

Используем brute force. Будем просто перебирать гиперпараметры и выбирать такие, где точность максимальна.

Для этого есть класс:

```
GridSearchCV(estimator=pipe, param_grid=param_grid,cv=10)
```

Тут мы задаем модель и массив словарей с параметрами, которые надо подогнать.

## Матрица несоответствий

Хотим построить вот такую матрицу:

![image](https://user-images.githubusercontent.com/25401699/223067030-20f76683-1ba2-4a38-8736-0e0683d8b3a5.png)

Для этого есть функция:

```
confusion_matrix(y_test, y_pred)
```

## Метрики

* Точность

$$
PRE = \frac{TP}{TP + FP}
$$

```
precision_score(y_test, y_pred)
```

* Полнота

$$
REC = \frac{TP}{FN + TP}
$$

```
recall_score(y_test, y_pred)
```

* F1

$$
F1 = 2 \frac{PRE * REC}{PRE + REC}
$$

```
f1_score(y_test, y_pred)
```

## ROC-кривая

Как ее строить: сортируем полученные вероятности, далее идем из точки (0, 0).
У нас классфификация из двух классов. Имеем вероятность принадлености точки первому классу.
Теперь идем по отсортированному массиву. Если истинное значение - второй класс, то идем на шаг вправо,
если истинное значение первый класс, то вверх. Таким образом, чем больше площадь кривой, тем лучше наша модель.

![image](https://user-images.githubusercontent.com/25401699/223075612-16068446-6ad3-47df-a8ff-7a7d737e0dc9.png)
