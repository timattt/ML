# Регрессионый анализ

Предсказываем сначение непрерывной величины.
Самый простой пример - МНК.

## Seaborn

### Графики зависимости между признаками

С помощью библиотеки seaborn можно быстро строить графики зависимости признаков друг от друга.
Используем:
```sns.pairplot```

### Представление матрицы в виде графика

Также можно легко нарисовать матрицу. Например, матрицу корреляции.
Используем:
```sns.heatmap```

## Матрицы

### Ковариационная матрица

$$
cov(
\begin{pmatrix}
x_1 \\
x_2
\end{pmatrix},
\begin{pmatrix}
y_1 \\
y_2
\end{pmatrix}
) =
\begin{pmatrix}
\sigma_{x_1 y_1} & \sigma{x_1 y_2} \\
\sigma_{x_2 y_1} & \sigma{x_2 y_2}
\end{pmatrix}
$$

где

$$
\sigma_{x_i y_j} = \overline{(x_i - \overline{x_i})(y_j - \overline{y_j})}
$$

Показывает распределение векторов.

### Корреляционная матрица

Аналогично предыдущей, только компоненты нормированны. И по модулю меньше единицы.
Если коэф. корреляции равен единице, значит есть линейная зависимость.

$$
\sigma_{xy}' = \frac{\sigma_{xy}}{\sigma_{x} \sigma_{y}}
$$

### Вычисление коэф корреляции

В numpy есть метод ```np.corrcoef``` - он вычисляет матрицу корреляции.

## Линейная регрессия

В общем многомерном случае формула для весов такая:

$$
\vec \omega = (X^T X)^{-1} X^T y
$$

Или используем библиотечную функцию:

$$
LinearRegression().fit(X, y).predict(X_new)
$$

